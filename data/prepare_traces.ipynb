{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = \"reasoning_traces/aime_1983_2023_qwq-32b_traces_32768.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.sort_values(by=[\"Year\", \"Part\", \"Problem Number\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "qwq_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/QwQ-32b\")\n",
    "\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "\n",
    "\n",
    "# Compute the number of tokens per row\n",
    "def count_tokens(text):\n",
    "    \"\"\"Count the number of tokens in a text string using the loaded tokenizer.\"\"\"\n",
    "    return len(qwen_tokenizer.encode(text))\n",
    "\n",
    "\n",
    "def apply_s1_template(question, reasoning, attempt):\n",
    "    question = question.strip()\n",
    "    question += (\n",
    "        \"\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.\"\n",
    "    )\n",
    "\n",
    "    text = qwen_tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": question.strip()},\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"<|im_start|>think\\n\"\n",
    "                + reasoning.strip()\n",
    "                + \"\\n<|im_start|>answer\\n\"\n",
    "                + attempt.strip(),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=False,\n",
    "    )\n",
    "    return text\n",
    "\n",
    "\n",
    "def apply_r1_template(question, reasoning, attempt):\n",
    "    question = question.strip()\n",
    "    question += (\n",
    "        \"\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.\"\n",
    "    )\n",
    "\n",
    "    text = qwq_tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": question.strip()},\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"<think>\\n\"\n",
    "                + reasoning.strip()\n",
    "                + \"\\n</think>\\n\"\n",
    "                + attempt.strip(),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=False,\n",
    "    )\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply chat template to all rows in the dataframe\n",
    "df[\"templated_response\"] = df.apply(\n",
    "    lambda row: apply_s1_template(\n",
    "        row[\"Question\"],\n",
    "        row[\"Reasoning\"],\n",
    "        row[\"Solution Attempt\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "df[\"Token Count\"] = df[\"templated_response\"].apply(count_tokens)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0][\"templated_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of token count ratios\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Display some statistics about token counts\n",
    "print(\"\\nToken count statistics:\")\n",
    "print(f\"Min: {df['Token Count'].min()}\")\n",
    "print(f\"Max: {df['Token Count'].max()}\")\n",
    "print(f\"Mean: {df['Token Count'].mean():.2f}\")\n",
    "print(f\"Median: {df['Token Count'].median():.2f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[\"Token Count\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Token Count\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(\n",
    "    df[\"Token Count\"].mean(),\n",
    "    color=\"r\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Mean: {df['Token Count'].mean():.3f}\",\n",
    ")\n",
    "plt.axvline(\n",
    "    df[\"Token Count\"].median(),\n",
    "    color=\"g\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: {df['Token Count'].median():.3f}\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "count_exceeding_limit = len(df[df[\"Token Count\"] >= 32768 / 2])\n",
    "print(f\"Number of rows with Reasoning Token Count > 32768: {count_exceeding_limit}\")\n",
    "\n",
    "# Calculate percentage of rows exceeding the token limit\n",
    "percentage_exceeding = (count_exceeding_limit / len(df)) * 100\n",
    "print(f\"Percentage of rows exceeding token limit: {percentage_exceeding:.2f}%\")\n",
    "\n",
    "\n",
    "count_incorrect = len(df[df[\"Correct\"] == False])\n",
    "print(f\"Number of incorrect rows: {count_incorrect}\")\n",
    "\n",
    "percentage_incorrect = (count_incorrect / len(df)) * 100\n",
    "print(f\"Percentage of incorrect rows: {percentage_incorrect:.2f}%\")\n",
    "\n",
    "\n",
    "count_missing_box = len(df[~df[\"Solution Attempt\"].str.contains(\"boxed\")])\n",
    "print(f\"Number of missing box rows: {count_missing_box}\")\n",
    "\n",
    "percentage_missing_box = (count_missing_box / len(df)) * 100\n",
    "print(f\"Percentage of missing box rows: {percentage_missing_box:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows that exceed the token limit, are incorrect, or missing the boxed answer\n",
    "\n",
    "df = df[df[\"Token Count\"] < 32768]\n",
    "df = df[df[\"Correct\"] == True]\n",
    "df = df[df[\"Solution Attempt\"].str.contains(\"boxed\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the dataframe to the Hugging Face Hub in the train split\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "from tempfile import NamedTemporaryFile\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "# Create a DatasetDict with a train split\n",
    "from datasets import DatasetDict\n",
    "\n",
    "dataset_dict = DatasetDict({\"train\": hf_dataset})\n",
    "\n",
    "# Save the dataset to a temporary directory\n",
    "with NamedTemporaryFile(suffix=\".csv\", delete=False) as temp_file:\n",
    "    df.to_csv(temp_file.name, index=False)\n",
    "    temp_file_path = temp_file.name\n",
    "\n",
    "# Initialize the Hugging Face API client\n",
    "api = HfApi()\n",
    "\n",
    "# Get the API token from environment variable\n",
    "token = os.environ.get(\"HUGGINGFACE_CLI\")\n",
    "\n",
    "# Define repository details\n",
    "repo_id = \"jonathanyin/\" + path.split(\"/\")[-1].split(\".csv\")[0]\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "# Push the dataset to the Hub\n",
    "dataset_dict.push_to_hub(repo_id=repo_id, token=token)\n",
    "\n",
    "# Clean up the temporary file\n",
    "os.unlink(temp_file_path)\n",
    "\n",
    "print(f\"Successfully pushed dataframe to {repo_id} in the train split\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
